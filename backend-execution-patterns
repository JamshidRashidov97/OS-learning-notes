When in server we create a listener, the kernel of our server creates a socket & two queues: SYN and Accept. This queues lives in the kernel itself.


When client sends a Syn message  ----> Kernel adds that SYN to SYN queue. Then replies with SYN/ACK.
Then Client replies with ACK,
Kernel finds ACK that matches with the ACK that client sent. Then it removes the SYN from SYN queue to Accept queue.
Then the backend application reads the SYN from Accept queue and creates a connection.
Then file descriptor for connection is created.
(The file descriptor is essentially an index to an entry in the kernel's file table, which keeps track of all open files, sockets, pipes, etc.)


Connection is the instance of the socket. It is the file descriptor that is created when the connection is established.
The socket is what we listen on, the connection is what we read/write on.

You can have hundreds of connections to the same socket.






When client sends a Syn message  ---->
1) SYN packet is sent by the client.
The client's SYN packet reaches the NIC (Network Interface Controller) of the server.

2) NIC processes the Ethernet frame:
The NIC checks the destination MAC address. If it matches the NIC’s MAC address, the frame is passed up to the kernel for further processing.

3) Kernel processes the IP layer:
The kernel checks the destination IP address. If the IP matches the server's IP address, it processes the packet further.

4) TCP layer (Transport layer) processes the SYN packet:
The kernel's TCP stack recognizes the packet as a SYN (TCP connection request).
If there's a listening socket bound to the target port, the kernel adds the connection to the SYN queue (also called the backlog queue).

5) TCP three-way handshake:
The server responds with a SYN-ACK, and when the client sends an ACK back, the connection is established.

6) Connection is moved to the Accept queue:
Once the handshake is complete, the connection is moved from the SYN queue to the Accept queue (also called the established connection queue).

7) Backend application accepts the connection:
The backend application (which is listening for connections) calls accept() to retrieve a connection from the Accept queue.
A file descriptor (FD) is created for the accepted connection, allowing the application to read and write data over this connection.


Key corrections:
SYN queue and Accept queue (backlog queue and established queue) are part of the kernel's TCP stack, not separate entities sending packets to each other.
The backend application doesn't directly deal with SYN or ACK packets but interacts with the connection after it's fully established via the file descriptor.








A file descriptor created by kernel?
Yes, the file descriptor (FD) is created by the kernel, not the application itself.

When the backend application calls accept() (after a successful three-way handshake for the TCP connection), the kernel creates a new file descriptor that represents the newly established connection.
The file descriptor is essentially an index to an entry in the kernel's file table, which keeps track of all open files, sockets, pipes, etc.

Here’s how it works:

The kernel manages network sockets just like regular files, meaning every open socket is associated with a file descriptor.
When the connection is established (after the TCP handshake), the kernel assigns a file descriptor to this new connection.
The application can then use this file descriptor to send and receive data via system calls like read() and write() or through higher-level abstractions.
So, the file descriptor itself is created and managed by the kernel as part of its role in managing resources like files and network connections.






How Node.js uses file descriptors?
Node.js does use file descriptors, but it abstracts them away for most developers.
Under the hood, Node.js relies on the libuv library, which provides an asynchronous I/O framework and is responsible for interacting with the operating system to handle tasks like file system access,
network communication, and timers.

How Node.js Uses File Descriptors:
File I/O:

When you interact with the file system (e.g., using fs.open(), fs.readFile(), fs.write()), Node.js uses file descriptors behind the scenes.
For instance, when you call fs.open(), the underlying system call (like open() in Linux) returns a file descriptor, which Node.js uses to read from or write to the file.
Node.js abstracts this file descriptor into a file handle so that you don’t have to deal with the raw numbers.
Network Sockets:

For network connections (e.g., using net.createServer()), the server or client sockets are also tied to file descriptors. The operating system assigns a file descriptor for each socket that is opened.
Node.js, through libuv, uses these file descriptors to manage the socket connection.
When a new TCP connection is established, the kernel creates a file descriptor for it, and Node.js interacts with it through its event-driven, non-blocking I/O system.
Pipes and IPC (Inter-Process Communication):

When working with child processes (child_process.fork() or child_process.spawn()), Node.js can use file descriptors to manage pipes between the parent and child processes.
The pipes themselves are represented by file descriptors in the operating system.






TLS is done by backend, not OS. OS only provides the socket. The backend application is responsible for handling the TLS handshake and encryption/decryption of data.



So what's the problem with reading and sending?
If the backend doesn't read fast enough, the receive buffer is going to be full,
and if the receive buffer is full, the kernel cannot accept more data. So the client is going to suffer.
The client, they're going to send all these data and the kernel in the backend is not reading fast enough.
In other words, the kernel in the backend is not putting this data into the buffer. It just says, hey, I don't have space. Just drop it.
So it will drop the packet altogether because there is no memory.
As the memory allocated by the kernel for us in the kernel.
So receive queue is full and the clients will slow down because of that.




//Todo
Learn sliding window concept in TCP. How it is used to control the flow of data between sender and receiver?







QUICK for OS is just UDP.





Now let's take examples of backend architectures.

We need to define:
- Listener: The thread/process that calls `listen`, passing the port and address, and gets back the socket ID.
- Acceptor: The entity that calls `accept` on the socket ID to get file descriptors for connections.
- Reader: The entity that reads the connection.

A single backend process can handle all three roles, but responsibilities can be separated:
- One listener
- Multiple acceptors
- Multiple readers

This is where multithreading and multiple processes come into play. Let's see how popular applications handle this.


Single Listener, Acceptor and Reader Thread Execution Pattern
- A single thread handles listening, accepting, and reading connections.
- Example: A simple HTTP server in Python using the `socket` library.
- How it works: The server creates a single thread that listens for incoming connections.
When a connection is received, the same thread accepts the connection and reads data from it.
This pattern is simple but can become a bottleneck under high load since one thread handles all tasks.


Single Listener, Acceptor and Multiple Readers Thread Execution Pattern
- One thread listens and accepts connections, while multiple threads read data.
- Example: A web server in Java using the `ExecutorService` to handle multiple threads.
- How it works: The server has a single thread that listens for and accepts connections.
Once a connection is accepted, it is handed off to one of several reader threads that handle the data processing.
This pattern improves performance by distributing the workload of reading data across multiple threads.


Single Listener, Acceptor, Reader with Message Load Balancing Execution Pattern
- One thread listens, accepts, and reads, then distributes messages to worker threads.
- Example: A chat server in Node.js using the `cluster` module to distribute messages.
- How it works: A single thread listens for, accepts, and reads incoming connections.
After reading the data, it distributes the messages to a pool of worker threads for further processing.
This pattern helps balance the load and ensures that message processing is handled efficiently.


Multiple Accepter Threads on a Single Socket Execution Pattern
- Multiple threads accept connections on the same socket.
- Example: A high-traffic server in C using the `pthread` library to handle incoming connections.
- How it works: The server creates multiple threads that all listen on the same socket.
When a connection request arrives, any of the threads can accept it.
This pattern allows the server to handle a high number of incoming connections simultaneously, improving performance under heavy load.


Multiple Listeners, Acceptors and Readers with Socket Sharding Execution Pattern
- Multiple threads or processes listen, accept, and read on different sockets (sharded).
- Example: A load-balanced server in Go using the `net` package with multiple goroutines.
- How it works: The server uses multiple threads or processes, each with its own socket, to listen for, accept, and read connections.
This technique, known as socket sharding, distributes the incoming connections across multiple sockets, reducing contention and improving scalability.


Multiple listeners on the same port.
Socket sharding (SO_REUSEPORT) is a technique that allows multiple processes to bind to the same port on the same IP address.
So you shard the socket in multiple processes.








Idempotency:
Idempotency is the idea of having a request to be repeatable without changing the state on the backend and not making any troubles.


Imagine you're making a payment online and you click the "Pay" button. If the client times out, you might not know if the payment went through.
The request was actually sent to the server and processed, but the client didn't receive a confirmation.
So, the client might display a message asking you to try again. If you click "Pay" again, a new request will be sent.
This new request will go through the same process and reach the backend. The backend will process it as a new payment request.
This can lead to multiple payments being processed for the same transaction.

